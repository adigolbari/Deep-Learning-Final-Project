# ðŸš€ Deep Learning Final Project

This project enhances transformer-based language models, specifically **BERT**, to improve story-ending comprehension. By fine-tuning a pre-trained model, we refine its ability to evaluate narrative coherence and select the most suitable story ending.

## ðŸ”¹ Project Overview
- Fine-tunes **BERT** for contextual story understanding.
- Adapts and extends the **OpenAI fine-tune-transformer-lm** framework.
- Explores different training strategies, hyperparameter tuning, and dataset enhancements.

## ðŸ“‚ Code Structure
- **`Final_project_dl.ipynb`** â€“ Main notebook for training and evaluation.
- **`Final Project Report.pdf`** â€“ Comprehensive report detailing the project, methodologies, experiments, and results.

## ðŸ“– References
This project is based on the original implementation from:
- [OpenAI's fine-tune-transformer-lm](https://github.com/openai/finetune-transformer-lm).
