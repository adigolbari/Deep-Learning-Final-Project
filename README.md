# Deep Learning Final Project

This project focuses on enhancing transformer-based language models, specifically **BERT**, to improve story-ending comprehension. By fine-tuning a pre-trained model, we aim to refine its ability to evaluate narrative coherence and select the most suitable story ending.

## ðŸ”¹ Overview
- Fine-tunes **BERT** for contextual story understanding.
- Adapts and extends the **OpenAI fine-tune-transformer-lm** framework.
- Experiments with different training strategies, hyperparameter tuning, and dataset enhancements.

## ðŸ“‚ Code Structure
- **`Final_project_dl.ipynb`** â€“ Contains the adjusted and fine-tuned code for training and evaluation.

## ðŸ“– References
This project is based on the original implementation from:
- [OpenAI's fine-tune-transformer-lm](https://github.com/openai/finetune-transformer-lm).

## ðŸš€ How to Use
1. Clone the repository:
   ```sh
   git clone https://github.com/adigolbari/Deep-Learning-Final-Project.git
